<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MeelGroup on MeelGroup</title>
    <link>/</link>
    <description>Recent content in MeelGroup on MeelGroup</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Tue, 19 May 2020 00:00:00 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Designing New Phase Selection Heuristics</title>
      <link>/publication/sat20sm/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/sat20sm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Sparsity of XORs in Approximate Model Counting</title>
      <link>/publication/sat20abm/</link>
      <pubDate>Tue, 19 May 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/sat20abm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sparse Hashing for Scalable Approximate Model Counting: Theory and Practice</title>
      <link>/publication/lics-20-am/</link>
      <pubDate>Mon, 18 May 2020 00:00:01 +0800</pubDate>
      
      <guid>/publication/lics-20-am/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Approximate Counting of Minimal Unsatisfiable Subsets</title>
      <link>/publication/cav20bm/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/cav20bm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Manthan: A Data-Driven Approach for Boolean Function Synthesis</title>
      <link>/publication/cav20_manthan/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/cav20_manthan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tinted, Detached, and Lazy CNF-XOR solving and its Applications to Counting and Sampling</title>
      <link>/publication/cav20sgm/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/cav20sgm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Induction Models on N</title>
      <link>/publication/lpar20dms/</link>
      <pubDate>Sat, 16 May 2020 00:00:01 +0800</pubDate>
      
      <guid>/publication/lpar20dms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Two Papers accepted to &lt;a href=&#34;https://sat2020.idea-researchlab.org/&#34;&gt;SAT 2020&lt;/a&gt;. &lt;br&gt; 1. The first paper shows that the currently known bounds for sparse hashing are too weak to be used for algorithms such as ApproxMC. Authors: Durgesh Agarwal, Bhavishya and Kuldeep S. Meel &lt;br&gt; 2. The second paper proposes a new phase selection strategy for SAT solvers. Improving SAT solvers is just a very very hard job and we are excited about the improvements that our proposal brings to the world of SAT solving. Authors: Arijit Shaw and Kuldeep S. Meel</title>
      <link>/news/25042020/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0800</pubDate>
      
      <guid>/news/25042020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper on Sparse Hashing for Approximate Model counting accepted to &lt;a href=&#34;https://lics.siglog.org/lics20/&#34;&gt;LICS 2020&lt;/a&gt;. Authors: S. Akshay and Kuldeep S. Meel&lt;br&gt;One of the reviews: &#34;Rarely it is that there is a paper that proves a beautiful new theoretical result, explaining and simplifying previous work, and on top of that shows how it can be used to improve state-of-the-art practical algorithms. The paper &#34;Sparse hashing for scalable approximate model counting: theory and practice&#34; achieves exactly that.&#34;</title>
      <link>/news/10042020/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0800</pubDate>
      
      <guid>/news/10042020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper accepted to &lt;a href=&#34;https://easychair.org/smart-program/LPAR23/&#34;&gt;LPAR-23&lt;/a&gt;. The paper formalizes Induction Models on N extending the classical work of Henkin. Authors: A Dileep, Kuldeep S. Meel and Ammar F. Sabili</title>
      <link>/news/08042020/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0800</pubDate>
      
      <guid>/news/08042020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Three Papers accepted at &lt;a href=&#34;https://www.facebook.com/groups/cavconference/?fref=mentions&#34;&gt;Computer Aided Verification (CAV)&lt;/a&gt; 2020 conference.&lt;br&gt;1. The first paper proposes a new approach that combines sampling&#43;machine learning&#43;MaxSAT to achieve a significant progress in solving Boolean Functional Synthesis. Authors: Priyanka Golia, Subhajit Roy, and Kuldeep S. Meel&lt;br&gt;2. The second paper builds on our CNF-XOR solving paradigm (BIRD) and as a result, the new versions of ApproxMC and UniGen are faster than ever. Stay tuned for our releases. Authors: Mate Soos, Stephan Gocht, and Kuldeep S. Meel&lt;br&gt;3. The third paper proposes the first algorithm for approximate MUS counting. Authors: Jaroslav Bendik and Kuldeep S. Meel</title>
      <link>/news/06042020/</link>
      <pubDate>Mon, 06 Apr 2020 00:00:00 +0800</pubDate>
      
      <guid>/news/06042020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Study of Symmetry Breaking Predicates and Model Counting</title>
      <link>/publication/tacas20wuawmk/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0800</pubDate>
      
      <guid>/publication/tacas20wuawmk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sampling-based approach for quantittive quantitative verification of Deep Neural Nets. We propose a new attack agnostic metric adversarial hardness to capture the model&amp;apos;s robustness: &lt;a href=&#34;https://arxiv.org/pdf/2002.06864.pdf&#34;&gt;https://arxiv.org/pdf/2002.06864.pdf&lt;/a&gt;  Authors: Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel and Prateek Saxena.</title>
      <link>/news/18022020/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0800</pubDate>
      
      <guid>/news/18022020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alexey Ignatiev, Joao Marques-Silva, Kuldeep S. Meel and Nina Narodytska give a tutorial at the Tutorial Forum in AAAI&amp;apos;20: &lt;a href=&#34;https://aaai.org/Conferences/AAAI-20/aaai20tutorials/&#34;&gt;Rigorous Verification and Explanation of ML Models&lt;/a&gt;.</title>
      <link>/news/08022020/</link>
      <pubDate>Sat, 08 Feb 2020 00:00:00 +0800</pubDate>
      
      <guid>/news/08022020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NPAQ</title>
      <link>/software/npaq/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0800</pubDate>
      
      <guid>/software/npaq/</guid>
      <description>&lt;p&gt;Neural networks are increasingly employed in safety-critical domains. This has prompted interest in verifying or certifying logically encoded properties of neural networks. Prior work has largely focused on checking existential properties, wherein the goal is to check whether there exists any input that violates a given property of interest. However, neural network training is a stochastic process, and many questions arising in their analysis require probabilistic and quantitative reasoning, i.e., estimating how many inputs satisfy a given property. To this end, our paper proposes a novel and principled framework to quantitative verification of logical properties specified over neural networks. Our framework is the first to provide PAC-style soundness guarantees, in that its quantitative estimates are within a controllable and bounded error from the true count. We instantiate our algorithmic framework by building a prototype tool called NPAQ that enables checking rich properties over binarized neural networks. We show how emerging security analyses can utilize our framework in 3 applications: quantifying robustness to adversarial inputs, efficacy of trojan attacks, and fairness/bias of given neural networks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relevant Papers:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.comp.nus.edu.sg/~teodorab/papers/NPAQ.pdf&#34; title=&#34;CCS 2019&#34; target=&#34;_blank&#34;&gt;CCS 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
