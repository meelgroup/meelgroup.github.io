<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MeelGroup on MeelGroup</title>
    <link>/</link>
    <description>Recent content in MeelGroup on MeelGroup</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Assessing Heuristic Machine Learning Explanations with Model Counting  </title>
      <link>/publication/sat19_heu/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/sat19_heu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CrystalBall: Gazing in the Black Box of SAT Solving </title>
      <link>/publication/sat19_cball/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/sat19_cball/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Knowledge Compilation meets Uniform Sampling</title>
      <link>/post/kus/</link>
      <pubDate>Fri, 03 May 2019 11:06:17 +0530</pubDate>
      
      <guid>/post/kus/</guid>
      <description>&lt;p&gt;This blogpost is based on our (&lt;a href=&#34;https://smsharma1.github.io/&#34; target=&#34;_blank&#34;&gt;Shubham&lt;/a&gt;, &lt;a href=&#34;https://rahulguptakota.github.io/&#34; target=&#34;_blank&#34;&gt;Rahul&lt;/a&gt;, &lt;a href=&#34;https://www.cse.iitk.ac.in/users/subhajit/&#34; target=&#34;_blank&#34;&gt;Subhajit&lt;/a&gt; and &lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/&#34; target=&#34;_blank&#34;&gt;Kuldeep&lt;/a&gt;) &lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/Papers/lpar18.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; that got published in the procedings of International Conference on Logic for Programming, Artificial Intelligence and Reasoning (LPAR), 2018. The code is available &lt;a href=&#34;https://github.com/meelgroup/KUS&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. The primary contribution of this work is marrying knowledge compilation with uniform sampling to design a new uniform sampler KUS. The main result is that KUS is able to solve more number of benchmarks than existing state-of-the-art uniform and almost-uniform samplers beating them by orders of magnitude in terms of runtime:
&lt;img src=&#34;cactus.png&#34; alt=&#34;alt text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;h3&gt;Uniform Sampling&lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Given a boolean formula $F$, the idea of Uniform Sampling is to generate samples from the set of solutions of $F$ called $R_F$ using a generator $\mathcal{G}$ that guarantees:
$$\forall y \in R_F, \mathsf{Pr}\left[\mathcal{G}(F) = y\right] = \frac{1}{|R_F|},$$
Uniform sampling is a fundamental problem in computer science with wide range of applications ranging from bayesian analysis to software engineering and programming languages. Jerrum, Valiant, and Vazirani observed deep relationship between model counting and uniform sampling. In particular, they showed that given access to an exact model counter, one could design a uniform generator which requires only polynomially many queries to the exact model counter. On the other hand, knowledge compilation has been emerged as a vital task wherein a logical theory is compiled into a form that allows performing probabilistic inference in polynomial time. It is well known that there is a deep connection between probabilistic inference and model counting. In this context, one wonders if the recent advances in knowledge compilation can be harnessed to design a scalable uniform sampler. The primary contribution of this work is marrying knowledge compilation with uniform sampling to design a new algorithm, KUS, that performs uniform sampling, outperforming current state-of-the-art approximately uniform and uniform samplers.&lt;/p&gt;

&lt;p&gt;&lt;h3&gt; Knowledge Compilation and d-DNNF representation&lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;To deal with computational intractability of probabilistic reasoning, knowledge compilation seeks to compile a knowledge base, often represented as a propositional formula in CNF, to a target language. Thereafter, probabilistic reasoning tasks, which are often expressed as sequence of queries, are performed by querying the knowledge base in the target language. Deterministic Decomposable Negation Normal Form (d-DNNF) have emerged as a central target language in knowledge compilation community since several probabilistic reasoning tasks such as probabilistic inference, maximum a posteriori (MAP) can be answered in polynomial time in the size of d-DNNF. A boolean formula in Negation Normal Form (NNF) is said to be in d-DNNF if it satisfes the following properties:
&lt;ul&gt;
&lt;li&gt; Deterministic: We refer to an NNF as deterministic if the operands of OR in all wellformed Boolean formula in the NNF are mutually inconsistent.&lt;/li&gt;
&lt;li&gt;Decomposable: We refer to an NNF as decomposable if the operands of AND in all wellformed Boolean formula in the NNF are expressed in a mutually disjoint set of variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;ddnnf.png&#34; alt=&#34;alt_text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;d-DNNF of a boolean formula $F$ represent the set of satisfying assignment $R_F$
&lt;h3&gt;The algorithm&lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The central idea behind KUS is to first employ the state-of-the-art knowledge compilation approaches to compile a given CNF formula into d-DNNF form, and then performing only two passes over the d-DNNF representation to generate as many identically and independently distributed samples as specified by the user denoted by $s$.
&lt;img src=&#34;kus.png&#34; alt=&#34;alt_text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;KUS takes in a CNF formula $F$ and required number of samples s and returns a set of $s$ samples such that each sample is uniformly and independently drawn from the uniform distribution over the set of solutions $R_F$. KUS first invokes a d-DNNF compiler over the formula F to obtain its d-DNNF. Then, the subroutine Annotate is invoked that annotates d-DNNF by annotating each node with a tuple consisting of the number of solutions and the set of variables in the node&amp;rsquo;s corresponding sub-formula. Then, the subroutine Sampler is invoked that returns s uniformly and independently drawn samples using the properties of d-DNNF. Finally, KUS gives random assignment to the unassigned variables for each sample in the SampleList to account for unconstrained variables that do not appear in d-DNNF by invoking the subroutine RandomAssignment.
&lt;h3&gt;The Results&lt;/h3&gt;
Our experiments demonstrated that KUS outperformed both SPUR and UniGen2 state-of-the-art uniform and almost-uniform samplers by a factor of up to $3$ orders of magnitude in terms of runtime in some cases while achieving a geometric speedup of $1.7\times$ and $8.3\times$ over SPUR and UniGen2 respectively. The distribution generated by KUS is statistically indistinguishable from that generated by an ideal uniform sampler. Moreover, KUS is almost oblivious to the number of samples requested. Finally, we observe that KUS can benefit from different d-DNNF compilers, therefore suggesting development of portfolio samplers in future. One of the biggest advantage of KUS is in incremental sampling&amp;ndash;fetching multiple, relatively small-sized samples, repeatedly. The typical use case of iterative sampling can be in repeated invocation of a sampling tool until the objective (such as desired coverage or violation of property) is achieved. In incremental-sampling KUS achieves speedups of upto 3 orders of magnitude.
&lt;h3&gt;Conclusion&lt;/h3&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;In this work, we have proposed a new approach for uniform sampling that builds on breakthrough progress in knowledge compilation&lt;/li&gt;
&lt;li&gt;Experimentally we have demonstrated that KUS outperformed state-of-the-art uniform and almost-uniform samplers&lt;/li&gt;
&lt;li&gt;We believe that the success of KUS will motivate researchers in verification and knowledge compilation communities to investigate a broader set of logical forms amenable to efficient uniform generation&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>WAPS: Weighted and Projected Sampling </title>
      <link>/publication/tacas19/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/tacas19/</guid>
      <description></description>
    </item>
    
    <item>
      <title> IMLI: An Incremental Framework for MaxSAT-Based Learning of Interpretable Classification Rules </title>
      <link>/publication/aies19/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/aies19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BIRD: Engineering an Efficient CNF-XOR SAT Solver and its Applications to Approximate Model Counting</title>
      <link>/publication/aaai19_bird/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/aaai19_bird/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BOSPHORUS: Bridging ANF and CNF Solvers </title>
      <link>/publication/date-cscm19/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/date-cscm19/</guid>
      <description>&lt;p&gt;abstract = &amp;ldquo;Algebraic Normal Form (ANF) and Conjunctive Normal Form (CNF) are commonly used to encode problems in Boolean algebra. ANFs are typically solved via Gr&amp;rdquo;obner basis algorithms, often using more memory than is feasible; while CNFs are solved using SAT solvers, which cannot exploit the algebra of polynomials naturally. We propose a paradigm that bridges between ANF and CNF solving techniques: the techniques are applied in an iterative manner to learn facts to augment the original problems. Experiments on over 1,100 benchmarks arising from four different applications domains demonstrate that learnt facts can significantly improve runtime and enable more benchmarks to be solved. &amp;ldquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On testing of Uniform Samplers </title>
      <link>/publication/aaai19_testing/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/aaai19_testing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Hardness of Probabilistic Inference Relaxations</title>
      <link>/publication/aaai19_hardness/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0800</pubDate>
      
      <guid>/publication/aaai19_hardness/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Knowledge Compilation meets Uniform Sampling</title>
      <link>/publication/lpar2018/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0800</pubDate>
      
      <guid>/publication/lpar2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Not All FPRASs are Equal: Demystifying FPRASs for DNF-Counting </title>
      <link>/publication/cp2018/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0800</pubDate>
      
      <guid>/publication/cp2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MLIC: A MaxSAT-Based framework for learning interpretable classification rules</title>
      <link>/publication/mm18/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0800</pubDate>
      
      <guid>/publication/mm18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Network Reliability Estimation in Theory and Practice </title>
      <link>/publication/ress/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0800</pubDate>
      
      <guid>/publication/ress/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scalable Approximation of Quantitative Information Flow in Programs</title>
      <link>/publication/vmcai18/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0800</pubDate>
      
      <guid>/publication/vmcai18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On Hashing-Based Approaches to Approximate DNF-Counting </title>
      <link>/publication/fsttcs17/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0800</pubDate>
      
      <guid>/publication/fsttcs17/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
